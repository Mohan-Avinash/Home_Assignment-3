{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyAnVFQ51ZiF38vOK5skth"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rYS97OmV2SYS"},"outputs":[],"source":["\"\"\"\n","Character‑level text generation with an LSTM RNN.\n","Trains on Shakespeare (tiny subset) and samples text with temperature control.\n","\"\"\"\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import numpy as np\n","import pathlib\n","import os\n","import time\n","\n","# 1. Load Shakespeare text (about 1 MB)\n","path = tf.keras.utils.get_file(\n","    \"shakespeare.txt\",\n","    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",")\n","text = pathlib.Path(path).read_text(encoding=\"utf‑8\")\n","print(f\"Corpus length: {len(text):,} characters\")\n","\n","# 2. Character vocabulary & vectorisation\n","chars = sorted(set(text))\n","print(f\"Unique chars: {len(chars)}\")\n","char2idx = {u: i for i, u in enumerate(chars)}\n","idx2char = np.array(chars)\n","\n","def text_to_int(txt: str):\n","    return np.array([char2idx[c] for c in txt], dtype=np.int32)\n","\n","encoded = text_to_int(text)\n","\n","# Sequence length & dataset preparation\n","seq_len = 100\n","examples_per_epoch = len(text) // (seq_len + 1)\n","\n","char_dataset = tf.data.Dataset.from_tensor_slices(encoded)\n","sequences = char_dataset.batch(seq_len + 1, drop_remainder=True)\n","\n","def split_input_target(chunk):\n","    input_txt = chunk[:-1]\n","    target_txt = chunk[1:]\n","    return input_txt, target_txt\n","\n","seq_ds = sequences.map(split_input_target)\n","\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","ds = (\n","    seq_ds.shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","\n","# 3. Build the RNN model\n","vocab_size = len(chars)\n","embedding_dim = 64\n","rnn_units = 256\n","\n","model = tf.keras.Sequential(\n","    [\n","        layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[BATCH_SIZE, None]),\n","        layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer=\"glorot_uniform\"),\n","        layers.Dense(vocab_size),\n","    ]\n",")\n","\n","# Loss (logits)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer=\"adam\", loss=loss)\n","\n","# 4. Train\n","EPOCHS = 10\n","model.fit(ds, epochs=EPOCHS)\n","\n","# 5. Text generation (sampling one char at a time)\n","\n","def generate_text(model, start_string: str, num_chars: int = 500, temperature: float = 1.0):\n","    \"\"\"Generate text given a seed string and temperature.\"\"\"\n","    # Rebuild model for batch_size=1\n","    temp_model = tf.keras.Sequential(\n","        [\n","            layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[1, None]),\n","            layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer=\"glorot_uniform\"),\n","            layers.Dense(vocab_size),\n","        ]\n","    )\n","    temp_model.set_weights(model.get_weights())\n","\n","    input_eval = text_to_int(start_string)\n","    input_eval = tf.expand_dims(input_eval, 0)  # batch=1\n","    generated = []\n","\n","    temp_model.reset_states()\n","    for _ in range(num_chars):\n","        preds = temp_model(input_eval)\n","        preds = preds[:, -1, :] / temperature  # focus on last step & scale by temperature\n","        predicted_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n","\n","        input_eval = tf.expand_dims([predicted_id], 0)\n","        generated.append(idx2char[predicted_id])\n","\n","    return start_string + \"\".join(generated)\n","\n","# Sample with different temperatures\n","for temp in [0.5, 1.0, 1.5]:\n","    print(\"\\n\" + \"=\" * 20 + f\" Temperature {temp}\" + \"=\" * 20)\n","    print(generate_text(model, start_string=\"ROMEO:\", temperature=temp, num_chars=300))\n","\n","# -------------------------\n","# Temperature explanation:\n","# Lower values (e.g., 0.5) make the distribution sharper -> safer, repetitive text.\n","# Higher values (e.g., 1.5) flatten the distribution -> more randomness & creativity.\n","# -------------------------\n"]}]}